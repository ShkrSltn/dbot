# Improving the "Enriched Statements" Block in DigiBot

## Enhancing the Quality of Personalized Statements

Personalized statements aim to be more understandable, relevant, and engaging than template phrases. To achieve this, it's necessary to balance clarity of presentation with richness of detail. Research shows that personalized content adapted to the user engages audiences more effectively by providing a more meaningful and relevant experience​ (researchgate.net). In the context of DigiBot, this means that enriched statements should reflect the user's actual activities, speak in language familiar to them, and mention familiar contexts.

**Using user context.** The key technique is integrating information about the user (their role, tasks, industry) directly into the statement text. For example, the original template statement "I use technology in my teaching" is quite general on its own. If it's known that the user is a teacher, the phrase can be enriched to "I use interactive tools and online resources to make learning more engaging and accessible for students" – adding specific tools and the purpose of using technology​ (file-5cokqvwcfevuc9mzcxqjxh). This approach makes the statement immediately more meaningful and practical as it reflects a real scenario from the user's practice. In the conducted study, enriched phrases were rated by users as more relevant to their profession compared to the original templates​ (file-5cokqvwcfevuc9mzcxqjxh).

**Clarity and readability.** It's important to avoid overloading statements with unnecessary details and complex formulations. Personalization should not come at the expense of comprehensibility. According to the survey, original (non-enriched) statements are usually easier to understand, while personalized ones are more complex to read​ (file-5cokqvwcfevuc9mzcxqjxh)​ (file-5cokqvwcfevuc9mzcxqjxh). This is logical: by adding details, we lengthen the phrase and introduce new terms. Therefore, it's necessary to keep enriched statements as concise as possible, simplify language where possible, and explain new concepts if they are unavoidable. For example, instead of bureaucratic language and jargon – use simple words. Readability metrics (such as the Flesch-Kincaid index, etc.) can help automatically control text complexity and achieve a level understandable to a wide audience.

**Content value and user benefit.** A personalized statement should not only "insert" user data but also provide them with useful information about themselves. Ideally, the enriched phrase should reveal some nuances or positive aspects, thereby engaging the user. For example, if the template is: "I use social media for brand promotion," the enriched version might emphasize the value of this action: "I effectively utilize social media to establish contact with the audience and strengthen the brand's online presence." Here, results are added ("establish contact," "strengthen presence"), making the phrase more inspiring and meaningful.

Below is a comparative table of the properties of template and personalized statements:

| Criterion                          | Template Statement                              | Personalized Statement                                                                                                                                                  |
| ---------------------------------- | ----------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Clarity and simplicity of language | High (minimum words, simple language)           | May decrease when adding details – risk of more complex text​ (file-5cokqvwcfevuc9mzcxqjxh)​ (file-5cokqvwcfevuc9mzcxqjxh). Length and vocabulary should be controlled. |
| Relevance to user                  | Low: general character, without context binding | High: takes into account the user's role, tasks, industry​ (file-5cokqvwcfevuc9mzcxqjxh), contains recognizable situations and terminology.                             |
| Informativeness, details           | Minimum details, basic statement                | Higher: reveals details, adds examples, accents​ (file-5cokqvwcfevuc9mzcxqjxh). The user learns more about their actions/skills.                                        |
| Engagement                         | Limited – text doesn't "hook" personally        | Enhanced through personal significance of content​ (researchgate.net). The user feels the description is "about them," which stimulates interest.                       |

Table 1 – Comparison of template and personalized (enriched) statements.

As can be seen, the main advantage of personalized statements is the increase in relevance and detail, which potentially leads to better user engagement. However, this may come at the cost of readability. Therefore, the best approaches to forming enriched statements are as follows:

1. **Contextualization without losing meaning**: integrate the user's personal context, but preserve the original essence of the statement. The new description should remain semantically close to the original (for content accuracy), only expanding it​ (file-5cokqvwcfevuc9mzcxqjxh).

2. **Control of length and style**: an enriched statement should not grow into a cumbersome sentence. It is recommended to aim for 1-2 short sentences (e.g., ≤20 words), simplify complex constructions, and avoid specialized terms unless necessary. If details are not critical – it's better to shorten the text​ (file-5cokqvwcfevuc9mzcxqjxh).

3. **Focus on positive and concrete**: if possible, formulate the statement to emphasize the user's achievements or correct actions. Specifics (numbers, tools, results) make the description vivid. For example, instead of the vague "I work with data," it's better to say "I analyze data and extract insights from it for business."

4. **Tone and empathy**: the style of personalized text should be friendly and motivating so that the user feels supported. This distinguishes a lively enriched description from a dry template and also increases engagement.

Thus, the combination of correctly implemented user profile and careful attention to language clarity can significantly improve the quality of enriched statements. Users will note that such phrases "speak their language" and reflect their individual experience while remaining understandable and useful.

## Minimally Necessary User Data

Effective personalization requires information about the user, but it's important to reduce it to a reasonable minimum. Collecting excessive data is fraught with privacy problems and complexity for the user themselves (extra input fields, confidentiality concerns). DigiBot's strategy is to request only the information that is truly needed to adapt content and that the user is willing to provide without discomfort.

Key data for personalization:

1. **Role information (profession or field of activity).** This is probably the most valuable parameter. Knowing the user's professional role (e.g., teacher, marketer, developer), the system can generate content with a corresponding focus. Mentioning professional specifics immediately makes statements more personal and meaningful. This approach is close to role-based personalization, where users are grouped by similar characteristics for content adaptation​ (uprock.ru). It's enough to ask the user for their position/role or offer to choose a field of interest from a list – this will already be sufficient to adapt many statements to the context.

2. **Main tasks or user goal.** An additional level is to clarify what tasks or projects the user is currently working on, or what their goal is for taking the test. For example, the goal might be: "I want to assess my skills for career growth in \_\_\_." If such data is not available, one can limit to just the role. But even 1-2 clarifying questions about activities (for example: "Name one or two main tasks you solve at work") will help enrich statements more accurately (as in the examples: specific tasks of a teacher and marketer are integrated into the text​ (file-5cokqvwcfevuc9mzcxqjxh)). It's important that these questions are optional and simple so that the user doesn't experience difficulties in answering.

3. **Level of competence (if necessary).** Paradoxically, for a digital competency test, it's useful to know the user's preliminary self-assessment of skills (for example, whether they consider themselves a beginner or advanced). This will allow adapting the enrichment style. As the experiment showed, beginners prefer simpler, "standard" formulations, while experienced users are ready to perceive more complex descriptions​ (file-5cokqvwcfevuc9mzcxqjxh). Therefore, a brief question like "How do you assess your level of digital skills?" (with options: beginner, intermediate, advanced) can help adjust the tone: give beginners maximally clear, spelled-out statements, and experts – more detail-rich ones. However, this parameter should be collected carefully so as not to confuse the user; and it is secondary in importance after role/context.

When collecting any data, the principle of "privacy by default" applies. It's necessary to avoid requesting personal and sensitive data not directly related to the personalization task. For example, one should not require full name, age, exact workplace, income, etc. This information is excessive for the purpose of content adaptation but creates risks (both in terms of confidentiality and extra burden on the user). Studies emphasize: hyperpersonalization based on a large amount of data often goes against privacy and can cause anxiety in users​ (uprock.ru).

Necessary and safe parameters are usually depersonalized characteristics: profession, field of activity, level of experience. They are sufficient for the system to customize scenarios for the user and do not reveal their identity. In addition, such parameters are easily specified: typically, the user willingly reports their type of activity if they understand that it's for benefit (for example, to get a more accurate test result).

**Ease of data entry.** The DigiBot interface should make entering minimal information simple and unburdening. It's best to embed questions in a dialogue or questionnaire before the test, explaining why they are needed. For example: "Select your field so we can make the questions closer to your practice:" – and a list of industries or roles. Limit to 1-3 questions. You can use dropdown lists or icons with options so that the choice takes one click. It's important to make it clear that the data will not be misused anywhere: briefly notify that they are used only for test personalization, not transferred to third parties, etc., strengthening trust.

In the end, the minimal profile for DigiBot can consist of: (1) profession/role or area of work, (2) if desired – key task or goal, (3) optionally – self-assessment of skills. This set is sufficient to generate enriched statements that significantly exceed templates in relevance, without intruding into the user's private life. This approach is consistent with recommendations for balancing personalization and confidentiality: it's enough to know basic information (name can even not be requested), and deep real-time data is not required​ (uprock.ru). By collecting less but purposefully, DigiBot simplifies life for both itself and the user.

## Applying the "AI as a Judge" Approach

The concept of "AI as a Judge" implies using AI capabilities to evaluate and select content according to specified criteria, similar to how a human expert would do it. In a personalized testing system, this approach can be applied in several directions:

1. **Evaluation of user responses.** When a user gives a free response or self-assessment, an AI model can act as an automatic checker. Modern large language models (LLMs) are capable of analyzing open text responses and making judgments about their quality, completeness, and correctness. The LLM-as-a-Judge method is already actively used to evaluate the conclusions of other models and open responses, as it's a practical alternative to labor-intensive manual checking by a human​ (evidentlyai.com). In other words, we programmatically set evaluation criteria, and AI, through a special prompt, assigns a grade or response category. For example, for an answer to a digital literacy question, the criteria might be: accuracy (is it essentially correct), completeness (are key aspects covered), clarity of presentation. The model, having received the answer and these criteria, will assign a conditional "score" or verdict.

The advantage is speed and scalability: an AI "judge" will check as many answers as needed in a fraction of a second, without fatigue and subjective variation inherent to different people. Research notes that properly configured LLM evaluators can approach human experts in consistency, while being orders of magnitude faster and cheaper​ (eugeneyan.com). Moreover, AI judges are flexible: they are not limited to simple matching with a reference answer but can capture different formulations and even style, as a live teacher would do​ (evidentlyai.com).

Of course, it's important to consider limitations as well. Without proper configuration, AI may not always be reliable: for example, it might miss factual errors or show bias. Therefore, it's better to use advanced models (e.g., GPT-4 instead of GPT-3.5) and give them clear frameworks. Practitioners recommend simplifying evaluation scales to binary or rough categories (e.g., "complete answer / incomplete answer") – this way AI gets confused less​ (evidentlyai.com). Also, applying multiple evaluations with subsequent combination (e.g., asking for evaluation three times and taking the majority or average score) increases reliability​ (evidentlyai.com). With such measures, AI evaluation of answers can become quite high-quality. In DigiBot, this will allow instantly giving feedback to the user: for example, "Your answer reveals the main idea but misses details X and Y" – which is significantly more valuable than just right/wrong for a competency test.

2. **Selection of the best enriched statements.** When personalized statements are generated, AI can be used for automatic selection of the most successful formulations. Large language models are capable of comparing texts with each other and ranking them according to specified criteria​ (evidentlyai.com). In our case, the quality criteria for statements can be: clarity, relevance to the user's context, style (friendliness, motivational quality), semantic proximity to the original meaning, literacy.

The approach can be as follows: generate several variants of an enriched statement (for example, with different paraphrases or degrees of detail), and then submit them to the "judgment" of an AI assistant. AI in pairwise-comparison mode can sequentially compare pairs of variants and choose the best one​ (evidentlyai.com), or immediately assign each variant a score on a scale. In the professional environment, similar mechanisms are already being applied: for example, OpenAI, when training its models, used a judge model to compare answers ("best of N") before showing the best one to the user.

It's important that criteria need to be explicitly formulated in the prompt for the AI judge so that the evaluation coincides with our ideas of the "best" statement​ (evidentlyai.com). For example, ask: "Evaluate which of the two statements is clearer and at the same time contains more details related to the user's profession (teacher)." Such a request will direct the model to choose a balance of clarity and personalization. Using an AI judge in the content generation chain allows ensuring consistently high quality: even if the primary generation gave several average variants, the "judge" will discard the weak ones and keep the optimal one. This is especially valuable considering the diversity of users – the model will be able to select the best formulation for each one according to their context.

3. **Supporting the user in self-assessment (recommendations and feedback).** Besides the role of a checker, AI can act as a mentor giving advice during and after the test. Such an AI component analyzes the user's answers and conducts a dialogue aimed at increasing awareness and improving results. For example, if a user rated their skill low or gave an uncertain answer, AI can ask a leading question: "What prevented you from mastering this technology? Perhaps you should try such-and-such resource..."

Modern educational applications already use AI for personal feedback. In particular, systems with AI tutors give students instant hints and explanations instead of direct answers, which has proven effective. In one experiment, students were provided with a customized ChatGPT that gave hints and error correction instead of solving problems for them – as a result, performance improved significantly without deterioration in the final control​ (edutopia.org). This example demonstrates: an AI mentor who timely suggests and corrects the user's course can improve the quality of learning and self-assessment. For DigiBot, this means that after each section of the test, AI could, having analyzed the answers, provide personalized recommendations: for example, praise strengths ("You have an excellent understanding of data security") and indicate growth areas ("Pay attention to cloud services, it's an important skill now"). This approach transforms the test from a one-time check into an educational dialogue where the user receives valuable feedback for further development.

In addition, an AI assistant can answer the user's questions during the test if something is unclear (within permissible limits, without revealing correct answers). For example, the user might ask: "What is meant by this skill?" – and AI will explain neutrally so that the user can correctly assess themselves. This reduces frustration and makes the process more friendly. From a UX perspective, having a "smart assistant" inside the test increases trust: the user feels support, not dry evaluation.

**Privacy and control.** It's important that with all the advantages of "AI as a Judge," transparency must be maintained for the user. AI recommendations and evaluations should be presented so that the person has the opportunity to disagree with them or challenge them. For example, after an automatic evaluation of an answer, you can ask the user: "Do you agree with this assessment of your answer?" – this engages them in reflection. Also, any AI advice should be given in a respectful form so as not to demotivate. The correctly set tone of AI (politeness, tact) matters​ (evidentlyai.com).

Overall, the implementation of an "AI judge" at different stages – from checking answers to selecting formulations and dialoguing with the user – can significantly strengthen a personalized test. This ensures both objectivity in evaluation and high quality of generated content, as well as deeper interaction with the user through feedback.

## Comparison of Prompting Methods and Enrichment Techniques

For generating enriched statements in DigiBot, different prompt engineering approaches can be used. Two modes were experimentally tested: zero-shot (no examples) and few-shot (with several examples). Variability is also introduced by the volume of profile context transmitted in the prompt (for example, substitution of profession data). Below is a comparative analysis of these techniques and their influence on the characteristics of the output text.

**Few-shot vs Zero-shot.** With the zero-shot approach, the model receives only the instruction "enrich the statement taking into account the context" without shown input-output examples. In this mode, the LLM relies on a general understanding of the task from its training. This saves space in the prompt and is easier to implement (no need to prepare examples). However, quality may be less predictable: without examples, the model may generate statements very heterogeneous in style. Few-shot prompting, on the contrary, includes 2-5 examples of pairs "original -> enriched variant" for similar cases. The model, seeing a sample, begins to imitate the demonstrated style and logic of enrichment, which usually improves the quality of the result. OpenAI's research on GPT-3 showed that providing even a few examples significantly improves task accuracy compared to zero-shot​ (analyticsvidhya.com)​ (analyticsvidhya.com). In our case, few-shot helped set the right tone: for example, by showing examples of a teacher and marketer (as above), we "taught" the model to add interactive tools for the teacher, emphasis on online presence for the marketer, etc. to the statement. That is, few-shot provides more reliable relevance and structured enrichment. The disadvantage is a larger "context weight" in the request (examples take up tokens) and the need to prepare good examples in advance.

**Using profile context.** Regardless of the shot mode, user information should be transmitted in the prompt: at least briefly indicate the profession and related tasks. For example: "Context: Teacher helping students learn effectively. Primary tasks: integrating technology and creating engaging lessons. Original: ... Enrich this statement...". Such insertions direct the model to include precisely relevant content. Practice shows that without explicit context, the model may generate more general phrases (not much different from the template). Adding a profile (role, task) leads to the appearance of specifics – those very "enriching" details​ (file-5cokqvwcfevuc9mzcxqjxh).

At the same time, too abundant context can complicate the model's task. Don't overload the prompt with a large amount of unrelated information about the user – 1-2 aspects directly related to the statement are enough. For example, profession and one goal at work. A large-sized model can take into account context thousands of characters long, but extra information can lead to noise or unnecessary deviations from the topic. Therefore, context should be selected carefully and concisely.

**Control of semantic proximity.** One of the metrics of enrichment quality is how close the new text is in meaning to the original statement. The original statement usually reflects some fact ("I use technology in teaching"), and while enriching, one cannot lead the meaning astray. The few-shot approach partially insures against this, as examples demonstrate preservation of the essence. Additionally, one can automatically check the semantic proximity between the original and generated statement using embeddings and cosine similarity​ (file-5cokqvwcfevuc9mzcxqjxh)​ (file-5cokqvwcfevuc9mzcxqjxh). If the similarity is below a certain threshold, the output judge model (or repeated call) can reject such a variant as "gone too far." In practice, a correctly set prompt (for example: "... Enrich the statement by integrating the context and tasks, while preserving the original meaning.") keeps the model from distorting facts. Zero-shot mode, however, can sometimes add non-existent details – here too, limiting the volume of context and explicitly indicating not to make up extra helps.

**Readability and style with different methods.** Few-shot examples can dictate not only content but also style. If examples are written in simple language, then new statements will come out in the same style. Thus, few-shot can be deliberately used to control readability – include an example of optimal length and simplicity. Zero-shot, on the other hand, depends more on the internal styles of the model: it may generate a too academic or, conversely, conversational sentence if the tone is not explicitly specified. Therefore, in a zero-shot prompt, it's worth writing requirements for style (for example: "Use clear, concise language" / "Formulate simply and clearly").

The DigiBot experiment showed that enriched statements obtained with context and examples contain more details but became slightly more complex in language​ (file-5cokqvwcfevuc9mzcxqjxh). This indicates that balance is important: not to overdo it with complication. In comparison: originals were more understandable to the majority, personalized – more informative. The solution is to reduce unnecessary adjectives, break up long sentences. If the model tends to "grow" the text, you can apply the self-edit technique: after generation, ask AI to edit its own statement, making it shorter and simpler (essentially, a second pass with the instruction "simplify"). Such a two-step pipeline (first enrich, then simplify) coupled with checking by an AI expert will preserve both content and readability.

**User engagement.** Although it's difficult to automatically measure "engagement" with text, user preferences indirectly reflect it. In the survey, ~45% of respondents preferred personalized statements, and ~54% – original ones​ (file-5cokqvwcfevuc9mzcxqjxh)​ (file-5cokqvwcfevuc9mzcxqjxh). Interestingly, users of medium skill level more often valued personalization (55% vs 45%), while beginners tended toward simple formulations​ (file-5cokqvwcfevuc9mzcxqjxh). This means that a more experienced audience finds enriched, detailed statements more motivating (they "recognize themselves" in the description), while less confident ones may even be slightly scared by complex language. Consequently, the enrichment technique should be adaptive: perhaps for beginners, light enrichment is sufficient (minimum new terms), and for advanced – full enrichment (more nuances). This can be configured either at the generation stage (different prompts for different levels) or by post-processing (filtering too complex phrases if the user is a beginner).

Engagement is also related to emotional tone. Enriched statements can be slightly colored with a positive tonality – for example, "build a strong online presence" sounds more inspiring than the neutral "use social media for promotion". The user feels progress or significance of their actions. Here it's important not to slide into excessive praise, to maintain naturalness.

**Conclusions on technique comparison:** The few-shot approach with the inclusion of user context currently looks most effective for generating quality personalized statements – it gives the model examples to emulate and data to bind to the person. Zero-shot can also be applied (especially if examples are few or token economy is important), but then the instruction and limitations need to be more carefully written. In both cases, additional improvement techniques are useful: post-editing, evaluation by an AI judge, metric checks (for similarity, length, reading). As NLP technologies develop, alternatives can also be considered:

- **Fine-tuning the model for the enrichment task.** A separately trained model on a corpus of "primary statement -> enriched" could generate personalized phrases without examples each time. But this requires a significant amount of data and training effort. In 2023-2024, frameworks for LLM personalization through additional training on profiles appeared​ (openreview.net), but in the case of DigiBot, it's still more rational to use ready-made large models with correct prompting.

- **Template-generative hybrid.** One can combine templates and a generative approach: have prepared fragments for different profiles and insert them into a template. However, this reduces flexibility and scalability – it's unlikely that all combinations of roles and tasks can be manually foreseen. Therefore, pure AI-generative is more preferable, especially since with few-shot it already gives a good result.

In the end, recommendations for improving the enrichment technique are as follows: use precedent examples in the prompt, transmit minimum but sufficient context about the user, explicitly write the desired criteria for text quality, and then use a verifier model (second pass of AI) to track compliance with these criteria. Such a multi-stage prompting pipeline guarantees that enriched statements will be understandable, thematically appropriate, and interesting to the user.

## Conclusion and Recommendations

In summary, to improve the enrichment block in DigiBot, modern practices of content personalization and AI-based quality control should be implemented. Below are briefly listed the main recommendations:

1. **Personalize wisely**: Enriched statements should speak the user's language – include their profession, field, tasks – but remain concise and easy to understand. Introduce specifics in doses and always preserve the original meaning of the statement.

2. **Minimize collected data**: Ask the user only for what will really enhance personalization (role, field, possibly goals). Avoid excess. This will simplify UX and eliminate privacy risks. Store and use user data transparently and safely.

3. **Use AI for quality assessment**: Apply the "AI judge" model to check generated statements against key criteria (clarity, relevance, etc.) and to evaluate user responses. This will help scale the system without losing quality. Consider the limitations of such assessments and implement measures for consistency (e.g., simple scales, multiple checks).

4. **Support the user through dialogue with AI**: An AI assistant built into the test that gives hints, clarifies answers, and provides feedback will make the process of taking the test more useful and motivating. The user will receive personal recommendations for skill development, which increases the value of DigiBot as a learning tool.

5. **Experiment with prompt techniques**: Continue testing different prompt configurations. Based on comparison results, prefer the few-shot approach with examples, especially for complex cases. Use the capabilities of GPT-4/summer models for fine-tuning responses (e.g., chain-of-thought or self-refinement, if needed to improve logic).

6. **Focus on metrics and feedback**: After implementing updates, measure the effect – how user satisfaction indicators change, what types of statements they prefer. Metrics of semantic proximity, readability, and surveys after the test will help understand if improvements are going in the right direction. Remember that quality is in the eyes of the user: the best check is a positive reaction from the DigiBot audience.

Following these approaches, DigiBot will be able to generate personalized statements of a new level – understandable, appropriate, and motivating for each user. The combination of AI power and human-oriented UX design will create a truly individual experience of self-assessment of digital competencies, meeting modern requirements of 2023-2025 and best practices in the field of AI personalization.
